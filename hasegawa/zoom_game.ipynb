{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# face recognition\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "face_predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/mamon/items/bb2334eef596f8cacd9b\n",
    "# https://qiita.com/mimitaro/items/bbc58051104eafc1eb38\n",
    "def face_detect(img):\n",
    "    # 顔検出\n",
    "    img_gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    faces = face_detector(img_gry, 1)\n",
    "\n",
    "    # 検出した全顔に対して処理\n",
    "    for face in faces:\n",
    "        cv2.rectangle(img, tuple([face.left(),face.top()]), tuple([face.right(),face.bottom()]), (0, 0,255), thickness=2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture():\n",
    "    # カメラ画像の表示 ('q'入力で終了)\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    while(True):\n",
    "        ret, img = cap.read()\n",
    "        #img = cv2.resize(img , (int(img.shape[1]), int(img.shape[0])))\n",
    "\n",
    "        # 顔のランドマーク検出(2.の関数呼び出し)\n",
    "        img = face_detect(img)\n",
    "        #img = face_recog(img)\n",
    "\n",
    "        # 結果の表示\n",
    "        #cv2.imshow('img', cv2.resize(img , (int(img.shape[1]*2), int(img.shape[0]*2))))\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "        # 'q'が入力されるまでループ\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 後処理\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/mamon/items/bb2334eef596f8cacd9b\n",
    "# https://qiita.com/mimitaro/items/bbc58051104eafc1eb38\n",
    "def face_detect_trim(img):\n",
    "    # 顔検出\n",
    "    img_gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    faces = face_detector(img_gry, 1)\n",
    "\n",
    "    pos = [0,0,0,0]\n",
    "    landmark = [[]]\n",
    "    # 検出した全顔に対して処理\n",
    "    for face in faces:\n",
    "        # 顔のランドマーク検出\n",
    "        landmark = face_predictor(img_gry, face)\n",
    "        # 処理高速化のためランドマーク群をNumPy配列に変換(必須)\n",
    "        landmark = face_utils.shape_to_np(landmark)[60:68]\n",
    "\n",
    "        img = img[face.top():face.bottom(), face.left():face.right()]\n",
    "        #cv2.rectangle(img, tuple([face.left(),face.top()]), tuple([face.right(),face.bottom()]), (0, 0,255), thickness=2)\n",
    "        \n",
    "        landmark[:,0] -= face.left()\n",
    "        landmark[:,1] -= face.top()\n",
    "        pos.append([face.top(),face.bottom(),face.left(),face.right()])\n",
    "        # ランドマーク描画\n",
    "        for (x, y) in landmark:\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        break\n",
    "\n",
    "    return img, pos, landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_trim():\n",
    "    # カメラ画像の表示 ('q'入力で終了)\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    while(True):\n",
    "        ret, img = cap.read()\n",
    "        #img = cv2.resize(img , (int(img.shape[1]), int(img.shape[0])))\n",
    "\n",
    "        # 顔のランドマーク検出(2.の関数呼び出し)\n",
    "        img,_,_ = face_detect_trim(img)\n",
    "        #img = face_recog(img)\n",
    "\n",
    "        # 結果の表示\n",
    "        cv2.imshow('img', cv2.resize(img , (int(img.shape[1]*2), int(img.shape[0]*2))))\n",
    "        #cv2.imshow('img', img)\n",
    "\n",
    "        # 'q'が入力されるまでループ\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 後処理\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "avg = None\n",
    "\n",
    "while True:\n",
    "    # 1フレームずつ取得する。\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # グレースケールに変換\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # 比較用のフレームを取得する\n",
    "    if avg is None:\n",
    "        avg = gray.copy().astype(\"float\")\n",
    "        continue\n",
    "\n",
    "    # 現在のフレームと移動平均との差を計算\n",
    "    cv2.accumulateWeighted(gray, avg, 0.6)\n",
    "    frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg))\n",
    "\n",
    "    # デルタ画像を閾値処理を行う\n",
    "    thresh = cv2.threshold(frameDelta, 3, 255, cv2.THRESH_BINARY)[1]\n",
    "    # 画像の閾値に輪郭線を入れる\n",
    "    image, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    frame = cv2.drawContours(frame, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    # 結果を出力\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "before = None\n",
    "while True:\n",
    "    #  OpenCVでWebカメラの画像を取り込む\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # スクリーンショットを撮りたい関係で1/4サイズに縮小\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]/4), int(frame.shape[0]/4)))\n",
    "    # 加工なし画像を表示する\n",
    "    cv2.imshow('Raw Frame', frame)\n",
    "\n",
    "    # 取り込んだフレームに対して差分をとって動いているところが明るい画像を作る\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if before is None:\n",
    "        before = gray.copy().astype('float')\n",
    "        continue\n",
    "    # 現フレームと前フレームの加重平均を使うと良いらしい\n",
    "    cv2.accumulateWeighted(gray, before, 0.5)\n",
    "    mdframe = cv2.absdiff(gray, cv2.convertScaleAbs(before))\n",
    "    # 動いているところが明るい画像を表示する\n",
    "    cv2.imshow('MotionDetected Frame', mdframe)\n",
    "\n",
    "    # 動いているエリアの面積を計算してちょうどいい検出結果を抽出する\n",
    "    thresh = cv2.threshold(mdframe, 3, 255, cv2.THRESH_BINARY)[1]\n",
    "    # 輪郭データに変換しくれるfindContours\n",
    "    image, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0\n",
    "    target = contours[0]\n",
    "    for cnt in contours:\n",
    "         #輪郭の面積を求めてくれるcontourArea\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if max_area < area and area < 10000 and area > 1000:\n",
    "            max_area = area;\n",
    "            target = cnt\n",
    "\n",
    "    # 動いているエリアのうちそこそこの大きさのものがあればそれを矩形で表示する\n",
    "    if max_area <= 1000:\n",
    "        areaframe = frame\n",
    "        cv2.putText(areaframe, 'not detected', (0,50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255,0), 3, cv2.LINE_AA)\n",
    "    else:\n",
    "        # 諸般の事情で矩形検出とした。\n",
    "        x,y,w,h = cv2.boundingRect(target)\n",
    "        areaframe = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('MotionDetected Area Frame', areaframe)\n",
    "    # キー入力を1ms待って、k が27（ESC）だったらBreakする\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# キャプチャをリリースして、ウィンドウをすべて閉じる\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_opencv)",
   "language": "python",
   "name": "conda_opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
